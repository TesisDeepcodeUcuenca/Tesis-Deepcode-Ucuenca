{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi/ypfit+vfJRGTJiecxoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TesisDeepcodeUcuenca/Tesis-Deepcode-Ucuenca/blob/main/C%C3%B3digos%20convencionales/Turbo_c%C3%B3digos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la ejecución de estos códigos es necesario incluir las librerias de la biblioteca pyturbo en Google Drive, esta biblioteca se encuentra en: https://github.com/DaulPavid/pyturbo"
      ],
      "metadata": {
        "id": "k40bARoxfgOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcHEK2ptfNT3"
      },
      "outputs": [],
      "source": [
        "#@title Turbo códigos\n",
        "\n",
        "import sys\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from turbo import TurboEncoder, AWGN, TurboDecoder\n",
        "\n",
        "def canal_bsc(mensaje, ruido):\n",
        "    msg_bits = ((mensaje + 1)/2).astype(int)\n",
        "    msg_canal_bits = np.bitwise_xor(msg_bits, ruido)\n",
        "    msg_canal = (msg_canal_bits * 2) - 1\n",
        "    return msg_canal\n",
        "\n",
        "def calculate_ber(original_bits, decoded_bits):\n",
        "    error_count = sum([x != y for x, y in zip(original_bits, decoded_bits)])\n",
        "    ber = error_count / len(original_bits)\n",
        "    return ber\n",
        "def guardar_matriz_en_csv(matriz, nombre_archivo):\n",
        "    # Convertir la matriz a un DataFrame de pandas\n",
        "    df = pd.DataFrame(matriz.T)  # Transponer para que cada columna corresponda a una probabilidad\n",
        "\n",
        "    # Asignar nombres a las columnas como Probabilidad 1, Probabilidad 2, etc.\n",
        "    df.columns = [f'Probabilidad {i + 1}' for i in range(matriz.shape[0])]\n",
        "\n",
        "    # Guardar el DataFrame en un archivo CSV\n",
        "    df.to_csv(nombre_archivo, index=False)\n",
        "def turbo_encode(message_bits):\n",
        "    block_size = len(message_bits)\n",
        "    interleaver = random.sample(range(0, block_size), block_size)\n",
        "    encoder = TurboEncoder(interleaver)\n",
        "    encoded_vector = encoder.execute(message_bits)\n",
        "    return encoded_vector, interleaver\n",
        "\n",
        "def turbo_decode(received_vector, interleaver):\n",
        "    decoder = TurboDecoder(interleaver)\n",
        "    decoded_vector = decoder.execute(received_vector)\n",
        "    decoded_vector = [int(b > 0.0) for b in decoded_vector]\n",
        "    return decoded_vector\n",
        "\n",
        "def tanda_train(batch_size, block_len, code_rate, qs, _, progreso_tanda):\n",
        "    ber_q = np.zeros((len(qs), batch_size))\n",
        "    for j, q in enumerate(qs):\n",
        "        data = np.random.randint(0, 2, (batch_size, block_len, 1))\n",
        "        noise = np.random.binomial(1, q, size=(batch_size, (block_len*code_rate) + 6, 1)).astype(int)\n",
        "        for i in range(0, batch_size):\n",
        "            progreso_tanda.update(1)\n",
        "            raw_data = (data[i:i+1, :, :]).squeeze().squeeze()\n",
        "            batch_noise = (noise[i:i+1, :, :]).squeeze().squeeze()\n",
        "            encoded_vector, interleaver = turbo_encode(raw_data)\n",
        "            coded_antipodal = (encoded_vector * 2) - 1\n",
        "            channel_vector = canal_bsc(coded_antipodal, batch_noise)\n",
        "            decoded_vector = np.array(turbo_decode(channel_vector, interleaver))\n",
        "            received_data = decoded_vector[:len(raw_data)]\n",
        "            ber = calculate_ber(raw_data, received_data)\n",
        "            ber_q[j][i] = ber\n",
        "    return ber_q\n",
        "\n",
        "def guardar_csv(data, filename):\n",
        "    filepath = filename  # Ajusta la ruta según dónde quieras guardar el archivo\n",
        "    with open(filepath, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Q values', 'Average BER'])\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    names = [\"turbo_1_3.csv\"]\n",
        "\n",
        "    for name in names:\n",
        "        block_len = 50\n",
        "        batch_size = 100\n",
        "        code_rate = 3\n",
        "        num_block = 100000\n",
        "        num_test_batch = int(num_block/batch_size)\n",
        "        qs = np.linspace(0.0001, 0.15, 20)\n",
        "        num_epoch_test = 100\n",
        "\n",
        "        arrays_q_turbo = []\n",
        "        print(f\"Total:\", num_epoch_test, \"tandas\")\n",
        "        progreso_tanda = tqdm(total=num_epoch_test*20*batch_size, desc=f\"Progreso GENERAL\")\n",
        "        for _ in range(num_epoch_test):\n",
        "            ber_q_turbo = tanda_train(batch_size, block_len, code_rate, qs, _, progreso_tanda)\n",
        "            arrays_q_turbo.append(ber_q_turbo)\n",
        "            #progreso_tanda.update(1)\n",
        "\n",
        "        qs_reshaped = qs.reshape(20, 1)\n",
        "\n",
        "        turbo_stack = np.hstack(arrays_q_turbo)\n",
        "        turbo_data = np.hstack((qs_reshaped, turbo_stack))\n",
        "        guardar_matriz_en_csv(turbo_data, \"turbo_1_3.csv\")\n",
        "        print(turbo_data.shape)"
      ]
    }
  ]
}