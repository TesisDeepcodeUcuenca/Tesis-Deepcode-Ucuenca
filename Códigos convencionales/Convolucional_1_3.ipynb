{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3i+eAPbzcn5H3vPspJS90",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TesisDeepcodeUcuenca/Tesis-Deepcode-Ucuenca/blob/main/C%C3%B3digos%20convencionales/Convolucional_1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convolucional 1/3\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import commpy.channelcoding.convcode as cc\n",
        "import commpy.utilities as util\n",
        "import scipy.stats as stats  # Importar scipy.stats\n",
        "\n",
        "# Define la función BSC (Binary Symmetric Channel)\n",
        "def bsc(input_bits, p_t):\n",
        "    \"\"\"\n",
        "    Binary Symmetric Channel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_bits : 1D ndarray containing {0, 1}\n",
        "        Input array of bits to the channel.\n",
        "\n",
        "    p_t : float in [0, 1]\n",
        "        Transition/Error probability of the channel.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output_bits : 1D ndarray containing {0, 1}\n",
        "        Output bits from the channel.\n",
        "    \"\"\"\n",
        "    output_bits = input_bits.copy()\n",
        "    flip_locs = (np.random.rand(len(output_bits)) <= p_t)\n",
        "    output_bits[flip_locs] = 1 ^ output_bits[flip_locs]\n",
        "    return output_bits\n",
        "\n",
        "# Define los parámetros del código convolucional\n",
        "memory = np.array(3, ndmin=1)\n",
        "g_matrix = np.array((0o7, 0o7, 0o5), ndmin=2)  # Tasa de codificación 1/2\n",
        "trellis = cc.Trellis(memory, g_matrix)\n",
        "tb_depth = 5 * (memory[0] + 1)  # Profundidad de traceback recomendada\n",
        "\n",
        "# Probabilidades de error a probar\n",
        "#error_probabilities = np.linspace(0.0001, 0.15, 20)\n",
        "\n",
        "error_probabilities = np.array([0.134221053, 0.142110526, 0.15])\n",
        "\n",
        "\n",
        "\n",
        "# Número de tramas y longitud de cada mensaje\n",
        "num_block = 100000\n",
        "batch_size = 100\n",
        "num_messages_per_frame = 100\n",
        "message_length = 50\n",
        "num_epochs = 1\n",
        "\n",
        "# Almacena los BER promedio para cada probabilidad de error\n",
        "ber_results = {p_t: [] for p_t in error_probabilities}  # Diccionario para almacenar BER para cada probabilidad en cada época\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"\")\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(\" \")\n",
        "\n",
        "    for p_t in error_probabilities:\n",
        "        total_bit_errors = 0\n",
        "        total_bits = 0\n",
        "\n",
        "        print(f\"Simulating for error probability p_t={p_t}...\")\n",
        "\n",
        "        for _ in tqdm(range(int(num_block/batch_size))):\n",
        "            # Generar bits de mensaje aleatorios en un batch\n",
        "            message_bits_batch = np.random.randint(0, 2, (num_messages_per_frame, message_length))\n",
        "\n",
        "            # Codificar los bits del mensaje en un batch\n",
        "            coded_bits_batch = np.array([cc.conv_encode(message_bits, trellis) for message_bits in message_bits_batch])\n",
        "\n",
        "            #print(coded_bits_batch.shape)\n",
        "\n",
        "            # Pasar los bits codificados a través del canal BSC en un batch\n",
        "            received_bits_batch = np.array([bsc(coded_bits, p_t) for coded_bits in coded_bits_batch])\n",
        "            #print(received_bits_batch.shape)\n",
        "            # Decodificar los bits recibidos en un batch\n",
        "            decoded_bits_batch = np.array([cc.viterbi_decode(received_bits.astype(float), trellis, tb_depth) for received_bits in received_bits_batch])\n",
        "\n",
        "            # Calcular el número de errores de bit en un batch\n",
        "            for message_bits, decoded_bits in zip(message_bits_batch, decoded_bits_batch):\n",
        "                num_bit_errors = util.hamming_dist(message_bits, decoded_bits[:len(message_bits)])\n",
        "                total_bit_errors += num_bit_errors\n",
        "                total_bits += len(message_bits)\n",
        "\n",
        "        # Calcular la BER promedio para esta época\n",
        "        ber = total_bit_errors / total_bits\n",
        "        ber_results[p_t].append(ber)\n",
        "        print(f\"BER for p_t={p_t}: {ber}\")\n",
        "\n",
        "# Convertir los resultados en un DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Epoch': np.repeat(range(1, num_epochs + 1), len(error_probabilities)),\n",
        "    'Probabilidad de Error (p_t)': np.tile(error_probabilities, num_epochs),\n",
        "    'BER': [ber for sublist in ber_results.values() for ber in sublist]\n",
        "})\n",
        "\n",
        "# Guardar los resultados en un archivo CSV\n",
        "results_df.to_csv('ber_vs_probabilidades22.csv', index=False)\n",
        "\n",
        "# Calcular el promedio y el intervalo de confianza\n",
        "mean_ber = []\n",
        "conf_intervals = []\n",
        "\n",
        "for p_t in error_probabilities:\n",
        "    data = ber_results[p_t]\n",
        "    mean = np.mean(data)\n",
        "    confidence_interval = stats.t.interval(0.95, len(data)-1, loc=mean, scale=stats.sem(data))\n",
        "\n",
        "    mean_ber.append(mean)\n",
        "    conf_intervals.append(confidence_interval)\n",
        "\n",
        "# Convertir listas a arrays para facilitar la manipulación\n",
        "mean_ber = np.array(mean_ber)\n",
        "conf_intervals = np.array(conf_intervals)\n",
        "\n",
        "# Graficar los resultados\n",
        "plt.figure()\n",
        "plt.errorbar(error_probabilities, mean_ber,\n",
        "             yerr=[mean_ber - conf_intervals[:, 0], conf_intervals[:, 1] - mean_ber],\n",
        "             fmt='o', capsize=5)\n",
        "plt.xlabel('Probabilidad de error (p_t)')\n",
        "plt.ylabel('Tasa de Error de Bit (BER)')\n",
        "plt.title('BER promedio vs Probabilidad de Error con intervalos de confianza')\n",
        "plt.grid(True)\n",
        "# plt.xscale('log')  # Escala logarítmica para el eje x si es necesario\n",
        "plt.yscale('log')  # Escala logarítmica para el eje y\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "h6BGlJ84fXQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}