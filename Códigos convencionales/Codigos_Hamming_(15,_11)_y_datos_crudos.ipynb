{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/s8IGi4yj2hdTT9VGK/r+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TesisDeepcodeUcuenca/Tesis-Deepcode-Ucuenca/blob/main/C%C3%B3digos%20convencionales/Codigos_Hamming_(15%2C_11)_y_datos_crudos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjs598dEfORh"
      },
      "outputs": [],
      "source": [
        "#@title Codigos Hamming (15, 11) y datos crudos\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "def guardar_matriz_en_csv(matriz, nombre_archivo):\n",
        "    # Convertir la matriz a un DataFrame de pandas\n",
        "    df = pd.DataFrame(matriz.T)  # Transponer para que cada columna corresponda a una probabilidad\n",
        "\n",
        "    # Asignar nombres a las columnas como Probabilidad 1, Probabilidad 2, etc.\n",
        "    df.columns = [f'Probabilidad {i + 1}' for i in range(matriz.shape[0])]\n",
        "\n",
        "    # Guardar el DataFrame en un archivo CSV\n",
        "    df.to_csv(nombre_archivo, index=False)\n",
        "def canal_bsc(mensaje, ruido):\n",
        "    channel_message = np.bitwise_xor(mensaje, ruido)\n",
        "    return channel_message\n",
        "def hamming_data(bits):\n",
        "    matrix_dimension = int(np.ceil(np.log2(len(bits))))\n",
        "    potencias_de_dos = [2 ** i for i in range(matrix_dimension + 1)]\n",
        "    posiciones_info = [i for i in range(1, 2 ** matrix_dimension + 1) if i not in potencias_de_dos]\n",
        "    return posiciones_info, matrix_dimension\n",
        "def calculate_ber(original_bits, decoded_bits):\n",
        "    error_count = np.sum(original_bits != decoded_bits)\n",
        "    ber = error_count / len(original_bits)\n",
        "    return ber\n",
        "def hamming_decode(Rx_bits, posiciones_info):\n",
        "    uncoded_bits = []\n",
        "    parity_check = 0\n",
        "    for i, bit in enumerate(Rx_bits):\n",
        "        if bit:\n",
        "            parity_check ^= i\n",
        "    if parity_check != 0:\n",
        "        Rx_bits[parity_check] ^= 1\n",
        "    for pos in posiciones_info:\n",
        "        uncoded_bits.append(Rx_bits[pos])\n",
        "\n",
        "    return uncoded_bits\n",
        "def hamming_encode(bits, posiciones_info, matrix_dimension):\n",
        "    bits_data = list(enumerate(bits))\n",
        "    matriz_hamming = np.zeros(2**matrix_dimension, dtype=int)\n",
        "    bit_activados = np.zeros((matrix_dimension, ((2*matrix_dimension)-1)), dtype=int)\n",
        "    flags_paridad = np.zeros(matrix_dimension, dtype=int)\n",
        "    bits_paridad = np.zeros(matrix_dimension, dtype=int)\n",
        "    for i, pos in enumerate(posiciones_info): matriz_hamming[pos] = bits_data[i][1]\n",
        "    for i, pos in enumerate(posiciones_info):\n",
        "        pos_bin = format(pos, '04b')\n",
        "        for j in range(matrix_dimension):\n",
        "            if pos_bin[(matrix_dimension-1) - j] == '1':\n",
        "                bit_activados[j, flags_paridad[j]] = matriz_hamming[pos]\n",
        "                flags_paridad[j] += 1\n",
        "    # for i in range(0, len(matriz_hamming), 4):print(matriz_hamming[i:i+4])\n",
        "    for j in range(matrix_dimension):\n",
        "        for i in bit_activados[j]:\n",
        "            bits_paridad[j] ^= i\n",
        "        matriz_hamming[2 ** j] = bits_paridad[j]\n",
        "    return matriz_hamming\n",
        "def tanda_hamming(batch_size, noise_block_len, block_len, qs, _, name):\n",
        "    ber_q = np.zeros((len(qs), batch_size))\n",
        "    for j, q in enumerate(qs):\n",
        "        data = np.random.randint(0, 2, (batch_size, block_len, 1))\n",
        "        noise = np.random.binomial(1, q, size=(batch_size, noise_block_len, 1)).astype(int)\n",
        "        for i in range(0, batch_size):\n",
        "            raw_data = (data[i:i + 1, :, :]).squeeze().squeeze()\n",
        "            batch_noise = (noise[i:i + 1, :, :]).squeeze().squeeze()\n",
        "            posiciones_info, matrix_dimension = hamming_data(raw_data)\n",
        "            encoded_vector = hamming_encode(raw_data, posiciones_info, matrix_dimension)\n",
        "            channel_vector = canal_bsc(encoded_vector, batch_noise)\n",
        "            decoded_vector = hamming_decode(channel_vector, posiciones_info)\n",
        "            ber = calculate_ber(raw_data, decoded_vector)\n",
        "            ber_q[j][i] = ber\n",
        "    return ber_q\n",
        "def guardar_csv(data, filename):\n",
        "    filepath = filename  # Ajusta la ruta según dónde quieras guardar el archivo\n",
        "    with open(filepath, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Q values', 'Average BER'])\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "def tanda_raw(batch_size, block_len, qs, _, name):\n",
        "    ber_q = np.zeros((len(qs), batch_size))\n",
        "    for j, q in enumerate(qs):\n",
        "        data = np.random.randint(0, 2, (batch_size, block_len, 1))\n",
        "        noise = np.random.binomial(1, q, size=(batch_size,block_len, 1)).astype(int)\n",
        "        for i in range(0, batch_size):\n",
        "            raw_data = (data[i:i + 1, :, :]).squeeze().squeeze()\n",
        "            batch_noise = (noise[i:i + 1, :, :]).squeeze().squeeze()\n",
        "            channel_vector = canal_bsc(raw_data, batch_noise)\n",
        "            ber = calculate_ber(raw_data, channel_vector)\n",
        "            ber_q[j][i] = ber\n",
        "    return ber_q\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    block_len = 11\n",
        "    noise_block_len = 16\n",
        "    batch_size = 100\n",
        "    code_rate = 3\n",
        "    num_block = 100000\n",
        "    num_test_batch = int(num_block / batch_size)\n",
        "\n",
        "    qs = np.linspace(0.0001, 0.15, 20)\n",
        "    arrays_q_raw = []\n",
        "    arrays_q_HAM = []\n",
        "    print(f\"Total:\", num_test_batch, \"tandas\")\n",
        "    for _ in range(num_test_batch):\n",
        "        ber_q_HAM = tanda_hamming(batch_size, noise_block_len, block_len, qs, _,\"H1.csv\")\n",
        "        arrays_q_HAM.append(ber_q_HAM)\n",
        "        ber_q_raw = tanda_raw(batch_size, block_len, qs, _, \"RAW1.csv\")\n",
        "        arrays_q_raw.append(ber_q_raw)\n",
        "\n",
        "    qs_reshaped = qs.reshape(20, 1)\n",
        "\n",
        "    HAM_stack = np.hstack(arrays_q_HAM)\n",
        "    HAM_data = np.hstack((qs_reshaped, HAM_stack))\n",
        "    HAM_data_transposed = HAM_data.T\n",
        "    guardar_matriz_en_csv(HAM_data, \"raw50.csv\")\n",
        "\n",
        "    raw_stack = np.hstack(arrays_q_raw)\n",
        "    raw_data = np.hstack((qs_reshaped, raw_stack))\n",
        "    RAW_data_transposed = raw_data.T\n",
        "    guardar_matriz_en_csv(raw_data, \"raw50.csv\")\n",
        "\n",
        "\n",
        "    print(raw_data.shape)\n",
        "    print(HAM_data.shape)\n"
      ]
    }
  ]
}