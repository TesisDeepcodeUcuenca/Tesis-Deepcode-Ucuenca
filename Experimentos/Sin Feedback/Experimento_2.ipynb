{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdflE6fPKMcTKHUbjcWhhg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TesisDeepcodeUcuenca/Tesis-Deepcode-Ucuenca/blob/main/Experimentos/Sin%20Feedback/Experimento_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsZX2NL8TtVT"
      },
      "outputs": [],
      "source": [
        "#@title Deepcode: 2 Capas lineales Encoder 1 entradas, salidas 3 -> 2 Capas Lineales Decoder 3 entradas, 1 salida sin FEEDBACK, rate 1/3\n",
        "__author__ = 'yihanjiang'\n",
        "# Adding the *Receiver Encoding*\n",
        "import argparse\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import csv\n",
        "import locale\n",
        "import pandas as pd\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-init_nw_weight', type=str, default='default')\n",
        "    parser.add_argument('-code_rate', type=int, default=3)\n",
        "    parser.add_argument('-learning_rate', type = float, default=0.00085)\n",
        "    parser.add_argument('-batch_size', type=int, default=100)\n",
        "    parser.add_argument('-num_epoch', type=int, default=10)\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')\n",
        "    parser.add_argument('-block_len', type=int, default=50)\n",
        "    parser.add_argument('-num_block', type=int, default=100000)\n",
        "    parser.add_argument('-enc_num_layer', type=int, default=2)\n",
        "    parser.add_argument('-dec_num_layer', type=int, default=2)\n",
        "    parser.add_argument('-fb_num_layer',  type=int, default=2)\n",
        "    parser.add_argument('-enc_num_unit',  type=int, default=100)\n",
        "    parser.add_argument('-dec_num_unit',  type=int, default=100)\n",
        "    parser.add_argument('-fb_num_unit',   type=int, default=100)\n",
        "    parser.add_argument('-q_train', type=float, default=0.001, help='Valor de probabilidad q de entrenamiento')\n",
        "    parser.add_argument('-q_train_fb', type=float, default=0.0000001, help='Valor de probabilidad q de entrenamiento para feedback')\n",
        "    parser.add_argument('-q_test_start', type=float, default=0.001, help='Inicio de valores de q para pruebas')\n",
        "    parser.add_argument('-q_test_end', type=float, default=0.15, help='Fin de valores de q para pruebas')\n",
        "    parser.add_argument('-q_points', type=int, default=5, help='Número de puntos de probabilidad q')\n",
        "    parser.add_argument('-channel_mode', choices=['normalize', 'lazy_normalize', 'tanh'], default='lazy_normalize')\n",
        "    parser.add_argument('-enc_act', choices=['tanh', 'selu', 'relu', 'elu', 'sigmoid'], default='sigmoid')\n",
        "    parser.add_argument('--zero_padding', action='store_true', default=False, help='enable zero padding')\n",
        "    parser.add_argument(\"-f\", \"--file\", required=False)\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "#############################\n",
        "#                           #\n",
        "#    █████████   ██████████ #\n",
        "#   ███░░░░░███ ░░███░░░░░█ #\n",
        "#  ░███    ░███  ░███  █ ░  #\n",
        "#  ░███████████  ░██████    #\n",
        "#  ░███░░░░░███  ░███░░█    #\n",
        "#  ░███    ░███  ░███ ░   █ #\n",
        "#  █████   █████ ██████████ #\n",
        "# ░░░░░   ░░░░░ ░░░░░░░░░░  #\n",
        "#                           #\n",
        "#############################\n",
        "class AE(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(AE, self).__init__()\n",
        "        self.args             = args\n",
        "        # Encoder\n",
        "        self.enc_p2_linear_fwd   = torch.nn.Linear(1, args.enc_num_unit, bias=True)\n",
        "        self.enc_p2_linear    = torch.nn.Linear(args.enc_num_unit, 3)\n",
        "\n",
        "        #Decoder\n",
        "        #self.dec_lstm           = torch.nn.LSTM(args.code_rate,  args.dec_num_unit,\n",
        "        #                                   num_layers=2, bias=True, batch_first=True,\n",
        "        #                                   dropout=0, bidirectional=True)\n",
        "        self.dec_linear        = torch.nn.Linear(args.code_rate, args.dec_num_unit, bias=True)\n",
        "        self.dec_output        = torch.nn.Linear(args.dec_num_unit, 1)\n",
        "\n",
        "    def enc_act(self, inputs):\n",
        "        if self.enc_act == 'tanh':\n",
        "            return F.tanh(inputs)\n",
        "        elif self.enc_act == 'elu':\n",
        "            return F.elu(inputs)\n",
        "        elif self.enc_act == 'relu':\n",
        "            return F.relu(inputs)\n",
        "        elif self.enc_act == 'selu':\n",
        "            return F.selu(inputs)\n",
        "        elif self.enc_act == 'sigmoid':\n",
        "            return F.sigmoid(inputs)\n",
        "        else:\n",
        "            return F.tanh(inputs)\n",
        "\n",
        "    def forward(self, input, fwd_noise, fb_noise):\n",
        "        x_p1      = input\n",
        "        x_p1_norm = 2*x_p1-1\n",
        "        p1_code = x_p1\n",
        "\n",
        "        if self.args.zero_padding:\n",
        "            p1_rec  = torch.logical_xor(x_p1, fwd_noise[:,:,0].view(self.args.batch_size, self.args.block_len+1, 1) ).float()\n",
        "            p1_fb   = torch.logical_xor(p1_rec , fb_noise[:,:, 0].view(self.args.batch_size, self.args.block_len+1, 1) ).float()\n",
        "        else:\n",
        "            p1_rec  = torch.logical_xor(x_p1, fwd_noise[:,:,0].view(self.args.batch_size, self.args.block_len, 1) ).float()\n",
        "            p1_fb   = torch.logical_xor(p1_rec , fb_noise[:,:, 0].view(self.args.batch_size, self.args.block_len, 1) ).float()\n",
        "\n",
        "        #p1_fb_norm = 2*p1_fb - 1\n",
        "\n",
        "\n",
        "        for idx in range(input.shape[1]):\n",
        "            #if idx == 0:\n",
        "            #    input_tmp        = x_p1_norm[:,idx,:].view(self.args.batch_size, 1, 1)\n",
        "            #    x_fwd_p2  =        self.enc_act(self.enc_p2_linear_fwd(input_tmp))\n",
        "            #    x_tmp_p2         = self.enc_act(self.enc_p2_linear(x_fwd_p2))\n",
        "            #    x_p2_history     = x_tmp_p2\n",
        "\n",
        "            #else:\n",
        "            input_tmp        = x_p1_norm[:,idx,:].view(self.args.batch_size, 1, 1)\n",
        "            x_tmp_p2  =        self.enc_act(self.enc_p2_linear_fwd(input_tmp))\n",
        "            x_tmp_p2         = self.enc_act(self.enc_p2_linear(x_tmp_p2))\n",
        "            x_p2_history     = x_tmp_p2\n",
        "\n",
        "            x_tmp_p2  = torch.heaviside(x_tmp_p2 , torch.zeros(x_tmp_p2.shape, device=x_tmp_p2.device)).float()\n",
        "\n",
        "\n",
        "            if idx == 0:\n",
        "              x_tmp_p2_gen= x_tmp_p2\n",
        "\n",
        "            else:\n",
        "              x_tmp_p2_gen = torch.cat([x_tmp_p2_gen,x_tmp_p2 ], dim = 1)\n",
        "\n",
        "\n",
        "            #if idx == 0:\n",
        "            #    p2_code= x_tmp_p2\n",
        "\n",
        "            #else:\n",
        "            #    p2_code = torch.cat([p2_code,x_tmp_p2 ], dim = 1)\n",
        "\n",
        "\n",
        "            x_p2_rec    = torch.logical_xor(x_tmp_p2,  fwd_noise[:,idx,:].view(self.args.batch_size, 1, 3)).float()\n",
        "            #x_p2_fb     = torch.logical_xor(x_p2_rec, fb_noise[:,idx, 1:].view(self.args.batch_size, 1, 2)).float()\n",
        "\n",
        "            #fb_tmp      = 2*x_p2_fb-1\n",
        "\n",
        "            if idx == 0:\n",
        "                p2_code= x_tmp_p2\n",
        "                p2_rec = x_p2_rec\n",
        "                #p2_fb  = x_p2_fb\n",
        "            else:\n",
        "                p2_code = torch.cat([p2_code,x_tmp_p2 ], dim = 1)\n",
        "                p2_rec = torch.cat([p2_rec,x_p2_rec ], dim = 1)\n",
        "                #p2_fb  = torch.cat([p2_fb, x_p2_fb],   dim = 1)\n",
        "\n",
        "        dec_input = p2_rec\n",
        "\n",
        "        x_code = x_tmp_p2_gen\n",
        "        inputs_dec = 2*dec_input-1\n",
        "\n",
        "        #x_dec, hdec_tmp  = self.dec_lstm( inputs_dec.float() )\n",
        "        x_dec  = self.dec_linear( inputs_dec.float() )\n",
        "        x_dec     = F.sigmoid(self.dec_output(x_dec))\n",
        "        return x_dec, x_code\n",
        "####################\n",
        "#                  #\n",
        "#  ██████   ██████ #\n",
        "# ░░██████ ██████  #\n",
        "#  ░███░█████░███  #\n",
        "#  ░███░░███ ░███  #\n",
        "#  ░███ ░░░  ░███  #\n",
        "#  ░███      ░███  #\n",
        "#  █████     █████ #\n",
        "# ░░░░░     ░░░░░  #\n",
        "#                  #\n",
        "####################\n",
        "\n",
        "args = get_args()\n",
        "print(args)\n",
        "def errors_ber(y_true, y_pred):\n",
        "    if args.zero_padding:\n",
        "        t1 = torch.round(y_true[:,:-1,:])\n",
        "        t2 = torch.round(y_pred[:,:-1,:])\n",
        "    else:\n",
        "        t1 = torch.round(y_true[:,:,:])\n",
        "        t2 = torch.round(y_pred[:,:,:])\n",
        "\n",
        "    myOtherTensor = torch.not_equal(t1, t2).float()\n",
        "    k = sum(sum(myOtherTensor))/(myOtherTensor.shape[0]*myOtherTensor.shape[1])\n",
        "    return k\n",
        "def errors_bler(y_true, y_pred):\n",
        "\n",
        "    if args.zero_padding:\n",
        "        t1 = torch.round(y_true[:,:-1,:])\n",
        "        t2 = torch.round(y_pred[:,:-1,:])\n",
        "    else:\n",
        "        t1 = torch.round(y_true[:,:,:])\n",
        "        t2 = torch.round(y_pred[:,:,:])\n",
        "\n",
        "    decoded_bits = t1\n",
        "    X_test       = t2\n",
        "    tp0 = (abs(decoded_bits-X_test)).reshape([X_test.shape[0],X_test.shape[1]])\n",
        "\n",
        "    bler_err_rate = sum(torch.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
        "    return bler_err_rate\n",
        "\n",
        "def ber_pos(y_true, y_pred):\n",
        "    if args.zero_padding:\n",
        "        t1 = torch.round(y_true[:,:-1,:])\n",
        "        t2 = torch.round(y_pred[:,:-1,:])\n",
        "    else:\n",
        "        t1 = torch.round(y_true[:,:,:])\n",
        "        t2 = torch.round(y_pred[:,:,:])\n",
        "    dif = torch.not_equal(t1, t2).float()\n",
        "    suma_dif = (torch.sum(dif, dim=0))\n",
        "    promedio_errorxbit = suma_dif/(dif.shape[0])\n",
        "    return promedio_errorxbit\n",
        "\n",
        "def Guardar_resultados(BER_FINAL, args, model):\n",
        "    Q = [BER_FINAL[i] for i in range(len(BER_FINAL)) if i % 2 == 0]\n",
        "    ber = [BER_FINAL[i] for i in range(len(BER_FINAL)) if i % 2 != 0]\n",
        "    column_names = ['init_nw_weight', 'code_rate', 'learning_rate', 'batch_size', 'num_epoch', 'no_cuda',\n",
        "                    'block_len', 'num_block', 'enc_num_layer', 'dec_num_layer', 'fb_num_layer', 'enc_num_unit',\n",
        "                    'dec_num_unit', 'fb_num_unit', 'q_train', 'q_train_fb', 'q_test_start', 'q_test_end',\n",
        "                    'q_points', 'channel_mode', 'enc_act', 'zero_padding', 'file', 'BER_Par', 'BER_Impar', 'Model_Description']\n",
        "    csv_file_path = '/content/datos.csv'\n",
        "    model_description = str(model)\n",
        "    with open(csv_file_path, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=column_names)\n",
        "        writer.writeheader()\n",
        "        args_dict = vars(args)\n",
        "        writer.writerow(args_dict)\n",
        "        writer.writerow({'Model_Description': model_description})\n",
        "    csv_df = pd.read_csv(csv_file_path)\n",
        "    # Crear DataFrame con BER_PAR y BER_Impar\n",
        "    data = {'Probabilidad Q': Q, 'BER': ber}\n",
        "    ber_df = pd.DataFrame(data)\n",
        "    # Ruta del archivo Excel\n",
        "    excel_file_path = '/content/datos_con_args.xlsx'\n",
        "    # Guardar el DataFrame de BER en un archivo Excel\n",
        "    ber_df.T.to_excel(excel_file_path, index=True)\n",
        "    # Leer el archivo Excel en un DataFrame\n",
        "    excel_df = pd.read_excel(excel_file_path, index_col=0)\n",
        "    # Concatenar los DataFrames\n",
        "    df_concatenado = pd.concat([csv_df.T, excel_df])\n",
        "    # Ruta del archivo concatenado\n",
        "    concatenated_file_path = '/content/Resultados.xlsx'\n",
        "    # Guardar el DataFrame concatenado en un archivo Excel\n",
        "    df_concatenado.to_excel(concatenated_file_path, index=True)\n",
        "    # Descargar el archivo concatenado\n",
        "    files.download(concatenated_file_path)\n",
        "    return concatenated_file_path\n",
        "\n",
        "identity = str(np.random.random())[2:8]\n",
        "print('[ID]', identity)\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "if use_cuda:\n",
        "    model = AE(args).to(device)\n",
        "else:\n",
        "    model = AE(args)\n",
        "\n",
        "print(model)\n",
        "\n",
        "if args.init_nw_weight == 'default':\n",
        "    pass\n",
        "else:\n",
        "    model = torch.load(args.init_nw_weight)\n",
        "    model.args = args\n",
        "\n",
        "# Guardar los parámetros iniciales del modelo\n",
        "#initial_state_dict = model.state_dict()\n",
        "#torch.save(initial_state_dict, 'initial_model2.pth')\n",
        "\n",
        "initial_state_dict = torch.load('initial_model2.pth')\n",
        "model.load_state_dict(initial_state_dict)\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.learning_rate)\n",
        "test_ratio = 20\n",
        "num_train_block, num_test_block = args.num_block, args.num_block/test_ratio\n",
        "my_q_train = args.q_train\n",
        "my_q_train_fb = args.q_train_fb\n",
        "\n",
        "print('Traning Q is', my_q_train)\n",
        "\n",
        "################\n",
        "#              #\n",
        "#  ███████████ #\n",
        "# ░█░░░███░░░█ #\n",
        "# ░   ░███  ░  #\n",
        "#     ░███     #\n",
        "#     ░███     #\n",
        "#     ░███     #\n",
        "#     █████    #\n",
        "#    ░░░░░     #\n",
        "#              #\n",
        "################\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx in range(int(num_train_block/args.batch_size)):\n",
        "        if args.zero_padding:\n",
        "            X_train    = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "            X_train    = torch.cat([X_train, torch.zeros(args.batch_size, 1, 1)], dim=1)\n",
        "            fwd_noise =  torch.bernoulli(torch.full((args.batch_size, args.block_len+1, args.code_rate), my_q_train))\n",
        "            fb_noise =   torch.bernoulli(torch.full((args.batch_size, args.block_len+1, args.code_rate), my_q_train_fb))\n",
        "        else:\n",
        "            X_train    = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "            fwd_noise =  torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), my_q_train))\n",
        "            fb_noise =   torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), my_q_train_fb))\n",
        "\n",
        "        X_train, fwd_noise, fb_noise = X_train.to(device), fwd_noise.to(device), fb_noise.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, X_hat_train_code = model(X_train, fwd_noise, fb_noise)\n",
        "        loss = F.binary_cross_entropy(output, X_train)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10000 == 0:\n",
        "            print('Train Epoch: {} [{}/{} Loss: {:.6f}'.format(epoch, batch_idx, num_train_block/args.batch_size, loss.item()))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss /(num_train_block/args.batch_size)) )\n",
        "def test(qs):\n",
        "  model.eval()\n",
        "  torch.manual_seed(random.randint(0,1000))\n",
        "  print('Qs', qs)\n",
        "  num_train_block =  args.num_block\n",
        "  errorxbit_T = torch.zeros(1, args.block_len, 1).to(device)\n",
        "  promedio_errorxbit = torch.zeros(1, args.block_len, 1).to(device)\n",
        "  BER_FINAL = []\n",
        "  for q in qs:\n",
        "    test_ber, test_bler = .0, .0\n",
        "    with torch.no_grad():\n",
        "      num_test_batch = int(num_train_block / (args.batch_size * test_ratio))\n",
        "      for batch_idx in range(num_test_batch):\n",
        "        if args.zero_padding:\n",
        "          X_test = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "          X_test = torch.cat([X_test, torch.zeros(args.batch_size, 1, 1)], dim=1)\n",
        "          fwd_noise = torch.bernoulli(torch.full((args.batch_size, args.block_len + 1, args.code_rate), q))\n",
        "          fb_noise = torch.zeros((args.batch_size, args.block_len + 1, args.code_rate))\n",
        "\n",
        "        else:\n",
        "          X_test = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "          fwd_noise =  torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), q))\n",
        "          fb_noise =   torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), my_q_train_fb))\n",
        "\n",
        "        X_test, fwd_noise, fb_noise = X_test.to(device), fwd_noise.to(device), fb_noise.to(device)\n",
        "        X_hat_test, X_hat_test_code = model(X_test, fwd_noise, fb_noise)\n",
        "        X_hat_test.to(device)\n",
        "        X_hat_test_code.to(device)\n",
        "        test_ber += errors_ber(X_hat_test, X_test)\n",
        "        test_bler += errors_bler(X_hat_test, X_test)\n",
        "        promedio_errorxbit += ber_pos(X_hat_test,X_test)\n",
        "\n",
        "    promedio_errorxbit /= 1.0*num_test_batch\n",
        "    errorxbit_T = torch.add(errorxbit_T, promedio_errorxbit)\n",
        "    test_ber  /= 1.0*num_test_batch\n",
        "    test_bler /= 1.0*num_test_batch\n",
        "\n",
        "    print('Test Q',round(q,3) ,'with ber ', float(test_ber), 'with bler', float(test_bler))\n",
        "    BER_FINAL.append(q)\n",
        "    BER_FINAL.append(float(test_ber))\n",
        "\n",
        "  return errorxbit_T, BER_FINAL\n",
        "\n",
        "#PATH='torch_model_791480.pt'\n",
        "#model=torch.load(PATH)\n",
        "\n",
        "q_interval = (args.q_test_end - args.q_test_start)* 1.0 /  (args.q_points)\n",
        "qs = [q_interval* item + args.q_test_start for item in range(args.q_points)]\n",
        "\n",
        "history_errorxbit_Ta = torch.zeros(1, args.block_len, 1).to(device)\n",
        "\n",
        "for epoch in tqdm(range(1, args.num_epoch + 1)):\n",
        "    print(\" \")\n",
        "    train(epoch)\n",
        "    errorxbit_Ta, BER_FINAL = test(qs)\n",
        "\n",
        "    if epoch >= int((args.num_epoch + 1)*0.9):\n",
        "      history_errorxbit_Ta = torch.add(history_errorxbit_Ta, errorxbit_Ta)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "\n",
        "errorxbit_T_q = errorxbit_Ta/(len(qs))\n",
        "\n",
        "history_errorxbit_Tq = history_errorxbit_Ta/((len(qs))*((args.num_epoch + 1)-int((args.num_epoch + 1)*0.9)))\n",
        "\n",
        "\n",
        "#lista_errxbit_q = errorxbit_T_q.cpu().squeeze().squeeze().numpy()\n",
        "#lista_errxbit_q = errorxbit_T_q .squeeze().squeeze().numpy().to(device)\n",
        "\n",
        "history_errorxbit_Tq = history_errorxbit_Tq.cpu().squeeze().squeeze().numpy()\n",
        "\n",
        "print(BER_FINAL)\n",
        "lista = list(range(1, (args.block_len+1)))\n",
        "\n",
        "\n",
        "Guardar_resultados(BER_FINAL, args, model)\n",
        "#plt.plot(lista, lista_errxbit_q, marker='o', linestyle=':')\n",
        "plt.plot(lista, history_errorxbit_Tq, marker='o', linestyle=':')\n",
        "plt.xlabel('Posición de bit')\n",
        "plt.ylabel('BER')\n",
        "plt.title('BER del bit bk')\n",
        "plt.savefig('grafico.png')  # Guarda la figura como un archivo PNG\n",
        "plt.show()\n",
        "files.download('grafico.png')\n",
        "print(\"                                                                       \")\n",
        "print(\"                                          ███████╗    ██╗    ███╗   ██╗\")\n",
        "print(\"                                          ██╔════╝    ██║    ████╗  ██║\")\n",
        "print(\"                                          █████╗      ██║    ██╔██╗ ██║\")\n",
        "print(\"                                          ██╔══╝      ██║    ██║╚██╗██║\")\n",
        "print(\"                                          ██║         ██║    ██║ ╚████║\")\n",
        "print(\"                                          ╚═╝         ╚═╝    ╚═╝  ╚═══╝\")\n",
        "print(\"                                                                       \")\n",
        "print(model)\n",
        "#import pdb; pdb.set_trace()\n",
        "#torch.save(model, '/content/drive/MyDrive/Deepcode_pytorch/tmp/torch_model_'+identity+'.pt')\n",
        "\n",
        "#print('saved model', '/content/drive/MyDrive/Deepcode_pytorch/tmp/torch_model_'+identity+'.pt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Deepcode: 2 Capas lineales Encoder 1 entradas, salidas 2 -> 2 Capas Lineales Decoder 2 entradas, 1 salida sin FEEDBACK, rate 1/2\n",
        "__author__ = 'yihanjiang'\n",
        "# Adding the *Receiver Encoding*\n",
        "import argparse\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import csv\n",
        "import locale\n",
        "import pandas as pd\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-init_nw_weight', type=str, default='default')\n",
        "    parser.add_argument('-code_rate', type=int, default=2)\n",
        "    parser.add_argument('-learning_rate', type = float, default=0.00085)\n",
        "    parser.add_argument('-batch_size', type=int, default=100)\n",
        "    parser.add_argument('-num_epoch', type=int, default=10)\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')\n",
        "    parser.add_argument('-block_len', type=int, default=50)\n",
        "    parser.add_argument('-num_block', type=int, default=100000)\n",
        "    parser.add_argument('-enc_num_layer', type=int, default=2)\n",
        "    parser.add_argument('-dec_num_layer', type=int, default=2)\n",
        "    parser.add_argument('-fb_num_layer',  type=int, default=2)\n",
        "    parser.add_argument('-enc_num_unit',  type=int, default=100)\n",
        "    parser.add_argument('-dec_num_unit',  type=int, default=100)\n",
        "    parser.add_argument('-fb_num_unit',   type=int, default=100)\n",
        "    parser.add_argument('-q_train', type=float, default=0.15, help='Valor de probabilidad q de entrenamiento')\n",
        "    parser.add_argument('-q_train_fb', type=float, default=0.0000001, help='Valor de probabilidad q de entrenamiento para feedback')\n",
        "    parser.add_argument('-q_test_start', type=float, default=0.001, help='Inicio de valores de q para pruebas')\n",
        "    parser.add_argument('-q_test_end', type=float, default=0.15, help='Fin de valores de q para pruebas')\n",
        "    parser.add_argument('-q_points', type=int, default=20, help='Número de puntos de probabilidad q')\n",
        "    parser.add_argument('-channel_mode', choices=['normalize', 'lazy_normalize', 'tanh'], default='lazy_normalize')\n",
        "    parser.add_argument('-enc_act', choices=['tanh', 'selu', 'relu', 'elu', 'sigmoid'], default='sigmoid')\n",
        "    parser.add_argument('--zero_padding', action='store_true', default=False, help='enable zero padding')\n",
        "    parser.add_argument(\"-f\", \"--file\", required=False)\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "#############################\n",
        "#                           #\n",
        "#    █████████   ██████████ #\n",
        "#   ███░░░░░███ ░░███░░░░░█ #\n",
        "#  ░███    ░███  ░███  █ ░  #\n",
        "#  ░███████████  ░██████    #\n",
        "#  ░███░░░░░███  ░███░░█    #\n",
        "#  ░███    ░███  ░███ ░   █ #\n",
        "#  █████   █████ ██████████ #\n",
        "# ░░░░░   ░░░░░ ░░░░░░░░░░  #\n",
        "#                           #\n",
        "#############################\n",
        "class AE(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(AE, self).__init__()\n",
        "        self.args             = args\n",
        "        # Encoder\n",
        "        self.enc_p2_linear_fwd   = torch.nn.Linear(1, args.enc_num_unit, bias=True)\n",
        "        self.enc_p2_linear    = torch.nn.Linear(args.enc_num_unit, 2)\n",
        "\n",
        "        #Decoder\n",
        "        #self.dec_lstm           = torch.nn.LSTM(args.code_rate,  args.dec_num_unit,\n",
        "        #                                   num_layers=2, bias=True, batch_first=True,\n",
        "        #                                   dropout=0, bidirectional=True)\n",
        "        self.dec_linear        = torch.nn.Linear(args.code_rate, args.dec_num_unit, bias=True)\n",
        "        self.dec_output        = torch.nn.Linear(args.dec_num_unit, 1)\n",
        "\n",
        "    def enc_act(self, inputs):\n",
        "        if self.enc_act == 'tanh':\n",
        "            return F.tanh(inputs)\n",
        "        elif self.enc_act == 'elu':\n",
        "            return F.elu(inputs)\n",
        "        elif self.enc_act == 'relu':\n",
        "            return F.relu(inputs)\n",
        "        elif self.enc_act == 'selu':\n",
        "            return F.selu(inputs)\n",
        "        elif self.enc_act == 'sigmoid':\n",
        "            return F.sigmoid(inputs)\n",
        "        else:\n",
        "            return F.tanh(inputs)\n",
        "\n",
        "    def forward(self, input, fwd_noise, fb_noise):\n",
        "        x_p1      = input\n",
        "        x_p1_norm = 2*x_p1-1\n",
        "        #p1_code = x_p1\n",
        "\n",
        "        #if self.args.zero_padding:\n",
        "        #    p1_rec  = torch.logical_xor(x_p1, fwd_noise[:,:,0].view(self.args.batch_size, self.args.block_len+1, 1) ).float()\n",
        "        #    p1_fb   = torch.logical_xor(p1_rec , fb_noise[:,:, 0].view(self.args.batch_size, self.args.block_len+1, 1) ).float()\n",
        "        #else:\n",
        "        #    p1_rec  = torch.logical_xor(x_p1, fwd_noise[:,:,0].view(self.args.batch_size, self.args.block_len, 1) ).float()\n",
        "        #    p1_fb   = torch.logical_xor(p1_rec , fb_noise[:,:, 0].view(self.args.batch_size, self.args.block_len, 1) ).float()\n",
        "\n",
        "        #p1_fb_norm = 2*p1_fb - 1\n",
        "\n",
        "\n",
        "        for idx in range(input.shape[1]):\n",
        "            #if idx == 0:\n",
        "            #    input_tmp        = x_p1_norm[:,idx,:].view(self.args.batch_size, 1, 1)\n",
        "            #    x_fwd_p2  =        self.enc_act(self.enc_p2_linear_fwd(input_tmp))\n",
        "            #    x_tmp_p2         = self.enc_act(self.enc_p2_linear(x_fwd_p2))\n",
        "            #    x_p2_history     = x_tmp_p2\n",
        "\n",
        "            #else:\n",
        "            input_tmp        = x_p1_norm[:,idx,:].view(self.args.batch_size, 1, 1)\n",
        "            x_tmp_p2  =        self.enc_act(self.enc_p2_linear_fwd(input_tmp))\n",
        "            x_tmp_p2         = self.enc_act(self.enc_p2_linear(x_tmp_p2))\n",
        "            x_p2_history     = x_tmp_p2\n",
        "\n",
        "            x_tmp_p2  = torch.heaviside(x_tmp_p2 , torch.zeros(x_tmp_p2.shape, device=x_tmp_p2.device)).float()\n",
        "\n",
        "\n",
        "            if idx == 0:\n",
        "              x_tmp_p2_gen= x_tmp_p2\n",
        "\n",
        "            else:\n",
        "              x_tmp_p2_gen = torch.cat([x_tmp_p2_gen,x_tmp_p2 ], dim = 1)\n",
        "\n",
        "\n",
        "            #if idx == 0:\n",
        "            #    p2_code= x_tmp_p2\n",
        "\n",
        "            #else:\n",
        "            #    p2_code = torch.cat([p2_code,x_tmp_p2 ], dim = 1)\n",
        "\n",
        "\n",
        "            x_p2_rec    = torch.logical_xor(x_tmp_p2,  fwd_noise[:,idx,:].view(self.args.batch_size, 1, 2)).float()\n",
        "            #x_p2_fb     = torch.logical_xor(x_p2_rec, fb_noise[:,idx, 1:].view(self.args.batch_size, 1, 2)).float()\n",
        "\n",
        "            #fb_tmp      = 2*x_p2_fb-1\n",
        "\n",
        "            if idx == 0:\n",
        "                #p2_code= x_tmp_p2\n",
        "                p2_rec = x_p2_rec\n",
        "                #p2_fb  = x_p2_fb\n",
        "            else:\n",
        "                #p2_code = torch.cat([p2_code,x_tmp_p2 ], dim = 1)\n",
        "                p2_rec = torch.cat([p2_rec,x_p2_rec ], dim = 1)\n",
        "                #p2_fb  = torch.cat([p2_fb, x_p2_fb],   dim = 1)\n",
        "\n",
        "        dec_input = p2_rec\n",
        "\n",
        "        x_code = x_tmp_p2_gen\n",
        "        inputs_dec = 2*dec_input-1\n",
        "\n",
        "        #x_dec, hdec_tmp  = self.dec_lstm( inputs_dec.float() )\n",
        "        x_dec  = self.dec_linear( inputs_dec.float() )\n",
        "        x_dec     = F.sigmoid(self.dec_output(x_dec))\n",
        "        return x_dec, x_code\n",
        "####################\n",
        "#                  #\n",
        "#  ██████   ██████ #\n",
        "# ░░██████ ██████  #\n",
        "#  ░███░█████░███  #\n",
        "#  ░███░░███ ░███  #\n",
        "#  ░███ ░░░  ░███  #\n",
        "#  ░███      ░███  #\n",
        "#  █████     █████ #\n",
        "# ░░░░░     ░░░░░  #\n",
        "#                  #\n",
        "####################\n",
        "\n",
        "args = get_args()\n",
        "print(args)\n",
        "def errors_ber(y_true, y_pred):\n",
        "    if args.zero_padding:\n",
        "        t1 = torch.round(y_true[:,:-1,:])\n",
        "        t2 = torch.round(y_pred[:,:-1,:])\n",
        "    else:\n",
        "        t1 = torch.round(y_true[:,:,:])\n",
        "        t2 = torch.round(y_pred[:,:,:])\n",
        "\n",
        "    myOtherTensor = torch.not_equal(t1, t2).float()\n",
        "    k = sum(sum(myOtherTensor))/(myOtherTensor.shape[0]*myOtherTensor.shape[1])\n",
        "    return k\n",
        "def errors_bler(y_true, y_pred):\n",
        "\n",
        "    if args.zero_padding:\n",
        "        t1 = torch.round(y_true[:,:-1,:])\n",
        "        t2 = torch.round(y_pred[:,:-1,:])\n",
        "    else:\n",
        "        t1 = torch.round(y_true[:,:,:])\n",
        "        t2 = torch.round(y_pred[:,:,:])\n",
        "\n",
        "    decoded_bits = t1\n",
        "    X_test       = t2\n",
        "    tp0 = (abs(decoded_bits-X_test)).reshape([X_test.shape[0],X_test.shape[1]])\n",
        "\n",
        "    bler_err_rate = sum(torch.sum(tp0,axis=1)>0)*1.0/(X_test.shape[0])\n",
        "    return bler_err_rate\n",
        "\n",
        "def ber_pos(y_true, y_pred):\n",
        "    if args.zero_padding:\n",
        "        t1 = torch.round(y_true[:,:-1,:])\n",
        "        t2 = torch.round(y_pred[:,:-1,:])\n",
        "    else:\n",
        "        t1 = torch.round(y_true[:,:,:])\n",
        "        t2 = torch.round(y_pred[:,:,:])\n",
        "    dif = torch.not_equal(t1, t2).float()\n",
        "    suma_dif = (torch.sum(dif, dim=0))\n",
        "    promedio_errorxbit = suma_dif/(dif.shape[0])\n",
        "    return promedio_errorxbit\n",
        "\n",
        "def Guardar_resultados(BER_FINAL, args, model):\n",
        "    Q = [BER_FINAL[i] for i in range(len(BER_FINAL)) if i % 2 == 0]\n",
        "    ber = [BER_FINAL[i] for i in range(len(BER_FINAL)) if i % 2 != 0]\n",
        "    column_names = ['init_nw_weight', 'code_rate', 'learning_rate', 'batch_size', 'num_epoch', 'no_cuda',\n",
        "                    'block_len', 'num_block', 'enc_num_layer', 'dec_num_layer', 'fb_num_layer', 'enc_num_unit',\n",
        "                    'dec_num_unit', 'fb_num_unit', 'q_train', 'q_train_fb', 'q_test_start', 'q_test_end',\n",
        "                    'q_points', 'channel_mode', 'enc_act', 'zero_padding', 'file', 'BER_Par', 'BER_Impar', 'Model_Description']\n",
        "    csv_file_path = '/content/datos.csv'\n",
        "    model_description = str(model)\n",
        "    with open(csv_file_path, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=column_names)\n",
        "        writer.writeheader()\n",
        "        args_dict = vars(args)\n",
        "        writer.writerow(args_dict)\n",
        "        writer.writerow({'Model_Description': model_description})\n",
        "    csv_df = pd.read_csv(csv_file_path)\n",
        "    # Crear DataFrame con BER_PAR y BER_Impar\n",
        "    data = {'Probabilidad Q': Q, 'BER': ber}\n",
        "    ber_df = pd.DataFrame(data)\n",
        "    # Ruta del archivo Excel\n",
        "    excel_file_path = '/content/datos_con_args.xlsx'\n",
        "    # Guardar el DataFrame de BER en un archivo Excel\n",
        "    ber_df.T.to_excel(excel_file_path, index=True)\n",
        "    # Leer el archivo Excel en un DataFrame\n",
        "    excel_df = pd.read_excel(excel_file_path, index_col=0)\n",
        "    # Concatenar los DataFrames\n",
        "    df_concatenado = pd.concat([csv_df.T, excel_df])\n",
        "    # Ruta del archivo concatenado\n",
        "    concatenated_file_path = '/content/Resultados.xlsx'\n",
        "    # Guardar el DataFrame concatenado en un archivo Excel\n",
        "    df_concatenado.to_excel(concatenated_file_path, index=True)\n",
        "    # Descargar el archivo concatenado\n",
        "    files.download(concatenated_file_path)\n",
        "    return concatenated_file_path\n",
        "\n",
        "identity = str(np.random.random())[2:8]\n",
        "print('[ID]', identity)\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "if use_cuda:\n",
        "    model = AE(args).to(device)\n",
        "else:\n",
        "    model = AE(args)\n",
        "\n",
        "print(model)\n",
        "\n",
        "if args.init_nw_weight == 'default':\n",
        "    pass\n",
        "else:\n",
        "    model = torch.load(args.init_nw_weight)\n",
        "    model.args = args\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.learning_rate)\n",
        "test_ratio = 1\n",
        "num_train_block, num_test_block = args.num_block, args.num_block/test_ratio\n",
        "my_q_train = args.q_train\n",
        "my_q_train_fb = args.q_train_fb\n",
        "\n",
        "print('Traning Q is', my_q_train)\n",
        "\n",
        "################\n",
        "#              #\n",
        "#  ███████████ #\n",
        "# ░█░░░███░░░█ #\n",
        "# ░   ░███  ░  #\n",
        "#     ░███     #\n",
        "#     ░███     #\n",
        "#     ░███     #\n",
        "#     █████    #\n",
        "#    ░░░░░     #\n",
        "#              #\n",
        "################\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx in range(int(num_train_block/args.batch_size)):\n",
        "        if args.zero_padding:\n",
        "            X_train    = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "            X_train    = torch.cat([X_train, torch.zeros(args.batch_size, 1, 1)], dim=1)\n",
        "            fwd_noise =  torch.bernoulli(torch.full((args.batch_size, args.block_len+1, args.code_rate), my_q_train))\n",
        "            fb_noise =   torch.bernoulli(torch.full((args.batch_size, args.block_len+1, args.code_rate), my_q_train_fb))\n",
        "        else:\n",
        "            X_train    = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "            fwd_noise =  torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), my_q_train))\n",
        "            fb_noise =   torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), my_q_train_fb))\n",
        "\n",
        "        X_train, fwd_noise, fb_noise = X_train.to(device), fwd_noise.to(device), fb_noise.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, X_hat_train_code = model(X_train, fwd_noise, fb_noise)\n",
        "        loss = F.binary_cross_entropy(output, X_train)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10000 == 0:\n",
        "            print('Train Epoch: {} [{}/{} Loss: {:.6f}'.format(epoch, batch_idx, num_train_block/args.batch_size, loss.item()))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss /(num_train_block/args.batch_size)) )\n",
        "def test(qs):\n",
        "  model.eval()\n",
        "  torch.manual_seed(random.randint(0,1000))\n",
        "  print('Qs', qs)\n",
        "  num_train_block =  args.num_block\n",
        "  errorxbit_T = torch.zeros(1, args.block_len, 1).to(device)\n",
        "  promedio_errorxbit = torch.zeros(1, args.block_len, 1).to(device)\n",
        "  BER_FINAL = []\n",
        "  for q in qs:\n",
        "    test_ber, test_bler = .0, .0\n",
        "    with torch.no_grad():\n",
        "      num_test_batch = int(num_train_block / (args.batch_size * test_ratio))\n",
        "      for batch_idx in range(num_test_batch):\n",
        "        if args.zero_padding:\n",
        "          X_test = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "          X_test = torch.cat([X_test, torch.zeros(args.batch_size, 1, 1)], dim=1)\n",
        "          fwd_noise = torch.bernoulli(torch.full((args.batch_size, args.block_len + 1, args.code_rate), q))\n",
        "          fb_noise = torch.zeros((args.batch_size, args.block_len + 1, args.code_rate))\n",
        "\n",
        "        else:\n",
        "          X_test = torch.randint(0, 2, (args.batch_size, args.block_len, 1), dtype=torch.float)\n",
        "          fwd_noise =  torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), q))\n",
        "          fb_noise =   torch.bernoulli(torch.full((args.batch_size, args.block_len, args.code_rate), my_q_train_fb))\n",
        "\n",
        "      X_test, fwd_noise, fb_noise = X_test.to(device), fwd_noise.to(device), fb_noise.to(device)\n",
        "      X_hat_test, X_hat_test_code = model(X_test, fwd_noise, fb_noise)\n",
        "      X_hat_test.to(device)\n",
        "      X_hat_test_code.to(device)\n",
        "      test_ber += errors_ber(X_hat_test, X_test)\n",
        "      test_bler += errors_bler(X_hat_test, X_test)\n",
        "      promedio_errorxbit += ber_pos(X_hat_test,X_test)\n",
        "\n",
        "    promedio_errorxbit /= 1.0*num_test_batch\n",
        "    errorxbit_T = torch.add(errorxbit_T, promedio_errorxbit)\n",
        "    test_ber  /= 1.0*num_test_batch\n",
        "    test_bler /= 1.0*num_test_batch\n",
        "\n",
        "    print('Test Q',round(q,3) ,'with ber ', float(test_ber), 'with bler', float(test_bler))\n",
        "    BER_FINAL.append(q)\n",
        "    BER_FINAL.append(float(test_ber))\n",
        "\n",
        "  return errorxbit_T, BER_FINAL\n",
        "\n",
        "#PATH='torch_model_791480.pt'\n",
        "#model=torch.load(PATH)\n",
        "\n",
        "q_interval = (args.q_test_end - args.q_test_start)* 1.0 /  (args.q_points)\n",
        "qs = [q_interval* item + args.q_test_start for item in range(args.q_points)]\n",
        "\n",
        "history_errorxbit_Ta = torch.zeros(1, args.block_len, 1).to(device)\n",
        "\n",
        "for epoch in tqdm(range(1, args.num_epoch + 1)):\n",
        "    print(\" \")\n",
        "    train(epoch)\n",
        "    errorxbit_Ta, BER_FINAL = test(qs)\n",
        "\n",
        "    if epoch >= int((args.num_epoch + 1)*0.9):\n",
        "      history_errorxbit_Ta = torch.add(history_errorxbit_Ta, errorxbit_Ta)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "\n",
        "errorxbit_T_q = errorxbit_Ta/(len(qs))\n",
        "\n",
        "history_errorxbit_Tq = history_errorxbit_Ta/((len(qs))*((args.num_epoch + 1)-int((args.num_epoch + 1)*0.9)))\n",
        "\n",
        "\n",
        "#lista_errxbit_q = errorxbit_T_q.cpu().squeeze().squeeze().numpy()\n",
        "#lista_errxbit_q = errorxbit_T_q .squeeze().squeeze().numpy().to(device)\n",
        "\n",
        "history_errorxbit_Tq = history_errorxbit_Tq.cpu().squeeze().squeeze().numpy()\n",
        "\n",
        "print(BER_FINAL)\n",
        "lista = list(range(1, (args.block_len+1)))\n",
        "\n",
        "\n",
        "Guardar_resultados(BER_FINAL, args, model)\n",
        "#plt.plot(lista, lista_errxbit_q, marker='o', linestyle=':')\n",
        "plt.plot(lista, history_errorxbit_Tq, marker='o', linestyle=':')\n",
        "plt.xlabel('Posición de bit')\n",
        "plt.ylabel('BER')\n",
        "plt.title('BER del bit bk')\n",
        "plt.savefig('grafico.png')  # Guarda la figura como un archivo PNG\n",
        "plt.show()\n",
        "files.download('grafico.png')\n",
        "print(\"                                                                       \")\n",
        "print(\"                                          ███████╗    ██╗    ███╗   ██╗\")\n",
        "print(\"                                          ██╔════╝    ██║    ████╗  ██║\")\n",
        "print(\"                                          █████╗      ██║    ██╔██╗ ██║\")\n",
        "print(\"                                          ██╔══╝      ██║    ██║╚██╗██║\")\n",
        "print(\"                                          ██║         ██║    ██║ ╚████║\")\n",
        "print(\"                                          ╚═╝         ╚═╝    ╚═╝  ╚═══╝\")\n",
        "print(\"                                                                       \")\n",
        "print(model)\n",
        "#import pdb; pdb.set_trace()\n",
        "#torch.save(model, '/content/drive/MyDrive/Deepcode_pytorch/tmp/torch_model_'+identity+'.pt')\n",
        "\n",
        "#print('saved model', '/content/drive/MyDrive/Deepcode_pytorch/tmp/torch_model_'+identity+'.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "NaZK-KMvViGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}